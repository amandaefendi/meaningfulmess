---
title: "STAT2003 - Assignment 2"
author: "Amanda Efendi & Nina Kumagai"
date: "13/10/2019"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Stationary Case
```{r}
stationary = read.csv("stationary.csv", header = TRUE, row.names = 1)
head(stationary)
```

```{r} 
st_anova = aov((1/MAPE) ~ phi * theta * Method, data = stationary)
summary(st_anova)
```

```{r}
step(st_anova)
```

```{r}
library(FrF2)
#MEPlot(st_anova)
```


# Non-Stationary Case
```{r}
nonstationary = read.csv("non-stationary.csv", header = TRUE, row.names = 1)
head(nonstationary)
```

```{r}
non_st_anova = aov(MAPE ~ theta * Method, data = nonstationary)
summary(non_st_anova)
```

```{r}
step(non_st_anova)
```

```{r}
library(FrF2)
MEPlot(non_st_anova)
```

Check for Normality and Homogeneity of Variance


High theta and low theta error is other way around for the STAT2003 assignment Q1 because inversing the model will make larger errors small and small errors large. This means that it is now the larger errors that show smaller error!

Make sure to use multidimensional krigging in the second question of the assignment. 


Applying inverse on non-stationary actually makes it fail the Levene test of homogeneity although it makes up for the other assumption of normality. But Levene homogeneity of variance is arguably the more important assumption to hold.

Thus the article does both stationary and non-stationary cases wrong!


# Question 2

```{r message = FALSE}
library(mvtnorm)
library(e1071)
```

## Stationary Process

```{r}
#Stationary process
#y <- arima.sim(n=100, model=list(ar=c(-0.9,0.9), ma=c(-0.9,0.9)), rand.gen=rnorm)]
set.seed(61)
arma.sim <- arima.sim(model=list(ar=-0.9,ma=-0.9),n=51)
arma.sim
ts.plot(arma.sim)
```

## Function for simulating data

```{r}
# Simulate ARIMA based on the phi and theta parameter as function input
# Output the result as a 51x1 matrix with each row having 51 sequences of ts data

simData <- function(phi,theta){
  all_training=NULL
  for (i in 1:50){
    arimaSet = arima.sim(model=list(ar=phi, ma=theta),n=51)
    all_training = rbind(all_training, arimaSet[1:51])
  }
  return(all_training)
}
```

```{r}
#LLdata means low setting for both phi and theta
#LLdata has 50 rows and 51 columns
set.seed(61)
LLdata = simData(-0.9,-0.9)
LHdata = simData(-0.9,0.9)
HHdata = simData(0.9, 0.9)
HLdata = simData(0.9, -0.9)
```



## TRIAL - start SVM prediction using first row

```{r}
# training data is column 1 to 50
# test data is column 51st
# we only use the first row to test out.. not sure how to run all 50 rows..
trainSVMDat = data.frame(timestamp=c(seq(1,50,1)),value=LHdata[1,1:50])
testSVMDat = data.frame(timestamp=1,value=LHdata[1,51])
```

```{r}
# svm(y~x,data=training)
# the epsilon, gamma and cost values were taken from the paper
# the syntax we used is "to predict value using timestamp"
# predict(trainingmodel, newdata=testset)
LHmodelSVM = svm(value~timestamp,data=trainSVMDat,epsilon=0.1,gamma=0.1,cost=10)
LHpredSVM = predict(LHmodelSVM,newdata=testSVMDat); LHpredSVM
```

```{r}
# MAPE is the prediction - actual data divided by the prediction
MAPE = (LHpredSVM - testSVMDat[,2])/LHpredSVM; abs(MAPE)
```

## Function for automating the generation of MAPE values in SVM (Nina did after Basement Cafe :))

```{r}
#Automating the MEAN ABSOLUTE VALUE of MAPE - 1 replication
calc_mape = function(data_name){
  mape_matrix = NULL
  for (i in 1:50){
      #create the training and testing dataset from the chosen dataset (as per input)
      #each train and test is only one row of the 50 rows dataset
      trainDat = data.frame(timestamp=c(seq(1,50,1)),value=data_name[i,1:50]);trainDat
      testDat = data.frame(timestamp=1,value=data_name[i,51])
      
      #create a SVM model with the paramteres taken from the paper
      modelSVM = svm(value~timestamp,data=trainDat,epsilon=0.1,gamma=0.1,cost=10)
      predSVM = predict(modelSVM,newdata=testDat)
      
      #calculate the MAPE and "append" the value into the matrix
      MAPE = (predSVM - testDat[,2])/predSVM
      mape_matrix = rbind(mape_matrix, MAPE)
  }
  #label <- paste("MAPE", data_name, sep = "_")
  #assign(label, mape_matrix)
  
  #return the absolute value of the mean of the 50 rows of MAPE
  return (abs(mean(mape_matrix)))
}
```

```{r}
#test code above :)
calc_mape(LLdata)
```

### Replicating the functions above 5 times for each setting

```{r}
#Calculate the MAPE again but for all 5 replications
#This is like a wrapper function
replicatedMAPE = function(phi, theta){
  replicates = NULL
  for (i in 1:5){
    #simulate the dataset again for 5 times
    dataset = simData(phi, theta)
    newRep = calc_mape(dataset)
    replicates = rbind(replicates, newRep)
  }
  return(replicates)
}
```

```{r}
set.seed(21)
dat05 = replicatedMAPE(-0.9,-0.9) #LL
dat10 = replicatedMAPE(-0.9,0.9)  #LH
dat15 = replicatedMAPE(0.9,-0.9)  #HL
dat20 = replicatedMAPE(0.9,0.9)   #HH
```

### Create the final dataset for MAPEs from Stationary

```{r}
simStationary = data.frame(phi=c(rep(-0.9,10), rep(0.9,10)), theta=c(rep(c(-0.9,0.9),2,each=5)), MAPE = rbind(dat05, dat10,dat15, dat20))
head(simStationary)
tail(simStationary)
```

## Plotting MAPE

```{r}
library(plotly)

p <- plot_ly(simStationary, x = ~MAPE, y = ~phi, z = ~theta, colors = c('#BF382A', '#0C4B8E')) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'MAPE'),
                     yaxis = list(title = 'Phi'),
                     zaxis = list(title = 'Theta')))
p
```

```{r}
library(lattice)
wireframe(MAPE ~ phi * theta, data = simStationary, scales = list(arrows = FALSE),drape = TRUE, colorkey = TRUE)
```

```{r}
library(lhs)
n=50
k=2
design=maximinLHS(n,k,dup=1)
plot(design)

designScaled = qunif(design,-1,1)
plot(designScaled)
```

```{r}
library(SPOT)
y = yvalue(designScaled[,1], designScaled[,2])
summary(y)
```

```{r}
# MAPE ~ phi * theta, data = simStationary

fit = buildKrigingDACE(simStationary$phi, simStationary$theta, simStationary$MAPE)
```

# Multi-dimensional krigging
# Linear (ANOVA)

# Optimality (finding best design)

```{r}

```

